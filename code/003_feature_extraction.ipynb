{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa7e11a-7a48-4456-96be-7f2ce4593e36",
   "metadata": {},
   "source": [
    "# Detecting Human Activities Through Smartphone Sensor - Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cec8d-559d-4c31-96c6-1a8720e8610f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa007308-9005-4b3d-9200-147b95675389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fftpack\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07962192-5bfd-40fd-8811-80e68d4ded3c",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a7079b-e784-4333-810a-7e524bfd5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LEN=3000\n",
    "WINDOW_OFFSET=200\n",
    "WINDOW_SIZE=200\n",
    "ACTIVITY_NAMES = [\"walking\", \"jogging\", \"stairs\", \"sitting\", \"standing\", \"typing\", \"brushing teeth\",\n",
    "                  \"eating soup\", \"eating chips\", \"eating pasta\", \"drinking from cup\", \"eating sandwich\",\n",
    "                  \"kicking soccer ball\", \"playing catch tennis ball\", \"dribbling basket ball\",\n",
    "                  \"writing\", \"clapping\", \"folding clothes\"]\n",
    "ACTIVITY_CODES_MAPPING = {'A': 'walking',\n",
    "                          'B': 'jogging',\n",
    "                          'C': 'stairs',\n",
    "                          'D': 'sitting',\n",
    "                          'E': 'standing',\n",
    "                          'F': 'typing',\n",
    "                          'G': 'brushing teeth',\n",
    "                          'H': 'eating soup',\n",
    "                          'I': 'eating chips',\n",
    "                          'J': 'eating pasta',\n",
    "                          'K': 'drinking from cup',\n",
    "                          'L': 'eating sandwich',\n",
    "                          'M': 'kicking soccer ball',\n",
    "                          'O': 'playing catch tennis ball',\n",
    "                          'P': 'dribbling basket ball',\n",
    "                          'Q': 'writing',\n",
    "                          'R': 'clapping',\n",
    "                          'S': 'folding clothes'}\n",
    "PBAR_FORMAT='{desc:12} {percentage:3.0f}%|{bar:27}| [ {n:4d}/{total:4d}, {elapsed}<{remaining}{postfix} ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f76fa8-e891-4ab6-914d-c9cc661d28fc",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113eff2-2475-4f52-a736-0d40a7109a3b",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37765ab-086a-4d26-be61-436ba082c52a",
   "metadata": {},
   "source": [
    "Average sensor value over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965a9889-c0ad-4bef-8d09-6029565e1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(a):\n",
    "    return a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b51d50-a544-42e6-af62-1dea6976206e",
   "metadata": {},
   "source": [
    "### Standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d99b67-18dc-41a7-a6eb-31758e2f8921",
   "metadata": {},
   "source": [
    "Standard deviation sensor value over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8a5068-642c-480f-989f-bd4b9d238f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stddev(a):\n",
    "    return np.std(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143790a4-744b-408e-b883-727f405fab5c",
   "metadata": {},
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9b9f8-d5f6-4dd5-8c8f-8aca52974ee9",
   "metadata": {},
   "source": [
    "Variance sensor value over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb073a7-225d-43f6-a378-7714101e0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var(a):\n",
    "    return np.var(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b7935f-fad6-444e-bede-c88e9d5610be",
   "metadata": {},
   "source": [
    "### Average absolute difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b71f2-230d-4044-9bd7-4c8c39257664",
   "metadata": {},
   "source": [
    "Average absolute difference over the window and the mean of those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c462c09-1e0c-4fc0-9338-ef265f890f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absoldev(a):\n",
    "    return np.mean(np.abs(a - np.mean(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf95434-b79c-4305-99ca-8037cbd92f92",
   "metadata": {},
   "source": [
    "### Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2634a-22c5-4a2c-a086-06258bcd7e7d",
   "metadata": {},
   "source": [
    "Cosine distance between pair of sensor values over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379c4c92-61cb-4629-b35a-9115c031624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d7b1d-d22f-4903-836c-907a49f4d3b1",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0707459-6413-49ff-be88-8037b9fcae4a",
   "metadata": {},
   "source": [
    "Correlation between pair of sensor values over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c32a941-21d6-425f-a8c4-5c5cb323da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cor(a, b):\n",
    "    return np.corrcoef(a,b)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ecec-7ece-454e-be2d-a9e20a7746b8",
   "metadata": {},
   "source": [
    "### Resultant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d739a-8432-4af1-aa22-1ab1a6961888",
   "metadata": {},
   "source": [
    "Average resultant value, computed by squaring each matching x, y, and z value, summing them, taking the square root, and then averaging these values over the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90eb0a98-3a13-4e1e-b737-1104bd45131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resultant(x, y, z):\n",
    "    resultant = np.sqrt(x**2 + y**2 + z**2)\n",
    "    average_resultant = np.mean(resultant)\n",
    "    return average_resultant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095243a-b647-4b43-b520-5c8b3c6f50e4",
   "metadata": {},
   "source": [
    "### Activity extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456b54fa-c69c-4be3-be44-5df1d8d9ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_activity(arr, data_length):\n",
    "    f = np.empty([data_length], dtype=arr.dtype)\n",
    "    for i in range(data_length):\n",
    "        start = i * WINDOW_OFFSET\n",
    "        f[i] = arr[start]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f9d84-ee9f-40ea-9459-f397f15bb909",
   "metadata": {},
   "source": [
    "### Binned distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba63014-f3eb-4910-8f7f-15037aae1ab4",
   "metadata": {},
   "source": [
    "A binned distribution, where the range of values in the 10s window (max â€“ min value), divide this range into 10 equal-sized bins, and then record the fraction of values in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db06a3e-8fb1-41d2-b376-b4e110cdbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_distribution(data):\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    bins = np.linspace(data_min, data_max, 11)  # 11 edges, so 10 bins\n",
    "    # Use np.histogram to calculate the histogram and the fraction of values in each bin\n",
    "    hist, _ = np.histogram(data, bins=bins)\n",
    "    # Normalize the histogram to get the fraction\n",
    "    bin_fractions = hist / len(data)\n",
    "    return np.array(bin_fractions)\n",
    "\n",
    "def calc_bindist(arr, bins, data_length):\n",
    "    f = np.zeros([data_length, bins])\n",
    "    for i in range(data_length):\n",
    "        start = i * WINDOW_OFFSET\n",
    "        f[i] = binned_distribution(arr[start:start+WINDOW_SIZE])\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c52f364-6615-468f-afca-1e0534aa9bc3",
   "metadata": {},
   "source": [
    "### MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12404a-6d47-41f1-8f81-4fe80709dfc4",
   "metadata": {},
   "source": [
    "MFCCs represent short-term power spectrum of a wave, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. There are 13 values per axis over the window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7ef6e4-dc73-4a61-ace4-72ca8fed8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(signal, sampling_rate=20, num_mfcc=13, frame_size=WINDOW_SIZE, hop_size=WINDOW_OFFSET, num_mels=40):\n",
    "    # Step 1: Frame the signal\n",
    "    num_frames = 1 + (len(signal) - frame_size) // hop_size\n",
    "    frames = np.zeros((num_frames, frame_size))\n",
    "    for i in range(num_frames):\n",
    "        start = i * hop_size\n",
    "        frames[i] = signal[start:start + frame_size] * np.hamming(frame_size)\n",
    "\n",
    "    # Step 2: Compute the FFT and Power Spectrum\n",
    "    n_fft = frame_size\n",
    "    fft = np.fft.rfft(frames, n=n_fft)\n",
    "    power_spectrum = (1.0 / n_fft) * (np.abs(fft) ** 2)\n",
    "\n",
    "    # Step 3: Apply Mel Filter Bank\n",
    "    mel_filters = np.zeros((num_mels, n_fft // 2 + 1))\n",
    "    mel_min = 0\n",
    "    mel_max = 2595 * np.log10(1 + (sampling_rate / 2) / 700)  # Convert max frequency to Mel scale\n",
    "    mel_points = np.linspace(mel_min, mel_max, num_mels + 2)  # Mel points\n",
    "    hz_points = 700 * (10 ** (mel_points / 2595) - 1)         # Convert Mel points back to Hz\n",
    "    bin_points = np.floor((n_fft + 1) * hz_points / sampling_rate).astype(int)  # FFT bin indices\n",
    "\n",
    "    for m in range(1, num_mels + 1):\n",
    "        mel_filters[m - 1, bin_points[m - 1]:bin_points[m]] = np.linspace(0, 1, bin_points[m] - bin_points[m - 1])\n",
    "        mel_filters[m - 1, bin_points[m]:bin_points[m + 1]] = np.linspace(1, 0, bin_points[m + 1] - bin_points[m])\n",
    "\n",
    "    mel_power = np.dot(power_spectrum, mel_filters.T)\n",
    "    mel_power = np.where(mel_power == 0, np.finfo(float).eps, mel_power)  # Avoid log(0)\n",
    "\n",
    "    # Step 4: Log Mel Spectrum\n",
    "    log_mel_power = np.log(mel_power)\n",
    "\n",
    "    # Step 5: Discrete Cosine Transform (DCT)\n",
    "    mfccs = scipy.fftpack.dct(log_mel_power, axis=1, norm='ortho')[:, :num_mfcc]\n",
    "\n",
    "    mfccs = mfccs.T  # Transpose to get shape (num_mfcc x num_frames)\n",
    "\n",
    "    mfccs =(mfccs - mfccs.min())/(mfccs.max()-mfccs.min())\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fcbba-2d2e-4bd7-98f3-411d22867e5d",
   "metadata": {},
   "source": [
    "### Utility for windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfa9f3-557f-4905-a941-21ae99e52eed",
   "metadata": {},
   "source": [
    "Code which performs windowing function over the time series sensor value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d573b494-5c48-427b-a799-7a332675951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window and perform opertion\n",
    "def sliding_window(arr, data_length, op):\n",
    "    f = np.zeros([data_length])\n",
    "    for i in range(data_length):\n",
    "        start = i * WINDOW_OFFSET\n",
    "        inp=[]\n",
    "        for a in arr:\n",
    "            inp.append(a[start:start+WINDOW_SIZE])\n",
    "        f[i] = op(*inp)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4814c518-f0ae-4f0e-9d7b-7b0a7ddf451f",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd520598-ef61-4b80-8fc3-ae71a95e5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTED_FEATURES = ['ACTIVITY',\n",
    "                        'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9',\n",
    "                        'Y0', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6', 'Y7', 'Y8', 'Y9',\n",
    "                        'Z0', 'Z1', 'Z2', 'Z3', 'Z4', 'Z5', 'Z6', 'Z7', 'Z8', 'Z9',\n",
    "                        'XAVG', 'YAVG', 'ZAVG',\n",
    "                        'XABSOLDEV', 'YABSOLDEV', 'ZABSOLDEV',\n",
    "                        'XSTANDDEV', 'YSTANDDEV', 'ZSTANDDEV',\n",
    "                        'XVAR', 'YVAR', 'ZVAR',\n",
    "                        'XMFCC0', 'XMFCC1', 'XMFCC2', 'XMFCC3', 'XMFCC4',\n",
    "                        'XMFCC5', 'XMFCC6', 'XMFCC7',\n",
    "                        'XMFCC8', 'XMFCC9', 'XMFCC10', 'XMFCC11', 'XMFCC12',\n",
    "                        'YMFCC0', 'YMFCC1', 'YMFCC2', 'YMFCC3', 'YMFCC4',\n",
    "                        'YMFCC5', 'YMFCC6', 'YMFCC7',\n",
    "                        'YMFCC8', 'YMFCC9', 'YMFCC10', 'YMFCC11', 'YMFCC12',\n",
    "                        'ZMFCC0', 'ZMFCC1', 'ZMFCC2', 'ZMFCC3', 'ZMFCC4',\n",
    "                        'ZMFCC5', 'ZMFCC6', 'ZMFCC7',\n",
    "                        'ZMFCC8', 'ZMFCC9', 'ZMFCC10', 'ZMFCC11', 'ZMFCC12',\n",
    "                        'XYCOS', 'XZCOS', 'YZCOS',\n",
    "                        'XYCOR', 'XZCOR', 'YZCOR',\n",
    "                        'RESULTANT',\n",
    "                        'PARTICIPANT'] # Categirical: 1600 -1650\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1099d9-01cb-4499-a0d2-3c4dd1d44dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_code(activity_names):\n",
    "    cat_len=len(activity_names)\n",
    "    activity_code={}\n",
    "    for idx, an in enumerate(activity_names):\n",
    "        for k in ACTIVITY_CODES_MAPPING.keys() :\n",
    "            if ACTIVITY_CODES_MAPPING[k]==an:\n",
    "                key = k\n",
    "        activity_code[key]=idx\n",
    "\n",
    "    assert(len(activity_code.keys())== cat_len)\n",
    "\n",
    "    print(f\"{activity_code}\")\n",
    "    print(f\"Number of Categories {cat_len}\")\n",
    "    return activity_code, cat_len\n",
    "\n",
    "def extract_feature(src_path, dst_path):\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "    filelist_train = sorted([txt for txt in os.listdir(src_path + \"/\") if txt[-4:] == \".txt\"])\n",
    "    filelist_train\n",
    "\n",
    "\n",
    "    activity_code, cat_len = get_activity_code(ACTIVITY_NAMES)\n",
    "    data_length = 1 + ((DATA_LEN * len(ACTIVITY_NAMES)) - WINDOW_SIZE) //WINDOW_OFFSET\n",
    "    print(f\"data length {data_length}\")\n",
    "    column_names = ['participant_id' , 'activity_code' , 'timestamp', 'x', 'y', 'z']\n",
    "    bak_file_cnt = 0\n",
    "    for idx, txt in enumerate(tqdm(filelist_train, desc=\"Extracting features\", bar_format=PBAR_FORMAT)):\n",
    "        df_out = pd.DataFrame()\n",
    "        df = pd.read_csv(src_path + txt, header = None, names = column_names, comment = \";\")\n",
    "        for k in activity_code.keys():\n",
    "            df_tmp = df[df['activity_code']==k][0:DATA_LEN]\n",
    "            if df_tmp.shape[0] !=DATA_LEN:\n",
    "                df_tmp = pd.read_csv(src_path + '/' + filelist_train[bak_file_cnt],\n",
    "                                          header = None,\n",
    "                                          names = column_names,\n",
    "                                          comment = \";\")\n",
    "                df_tmp = df_tmp[df_tmp['activity_code']==k][0:DATA_LEN]\n",
    "                bak_file_cnt = bak_file_cnt + 1\n",
    "            df_out = pd.concat([df_out, df_tmp])\n",
    "        x = df_out['x'].to_numpy()\n",
    "        y = df_out['y'].to_numpy()\n",
    "        z = df_out['z'].to_numpy()\n",
    "        df_processed = pd.DataFrame()\n",
    "        # AVG\n",
    "        f_x = sliding_window([x], data_length, get_avg)\n",
    "        f_y = sliding_window([y], data_length, get_avg)\n",
    "        f_z = sliding_window([z], data_length, get_avg)\n",
    "\n",
    "        df_processed['XAVG'] = f_x\n",
    "        df_processed['YAVG'] = f_y\n",
    "        df_processed['ZAVG'] = f_z\n",
    "\n",
    "        # VAR\n",
    "        f_x = sliding_window([x], data_length, get_var)\n",
    "        f_y = sliding_window([y], data_length, get_var)\n",
    "        f_z = sliding_window([z], data_length, get_var)\n",
    "        df_processed['XVAR'] = f_x\n",
    "        df_processed['YVAR'] = f_y\n",
    "        df_processed['ZVAR'] = f_z\n",
    "\n",
    "\n",
    "        # STDDEV\n",
    "        f_x = sliding_window([x], data_length, get_stddev)\n",
    "        f_y = sliding_window([y], data_length, get_stddev)\n",
    "        f_z = sliding_window([z], data_length, get_stddev)\n",
    "        df_processed['XSTANDDEV'] = f_x\n",
    "        df_processed['YSTANDDEV'] = f_y\n",
    "        df_processed['ZSTANDDEV'] = f_z\n",
    "\n",
    "        # ABSOLDEV\n",
    "        f_x = sliding_window([x], data_length, get_absoldev)\n",
    "        f_y = sliding_window([y], data_length, get_absoldev)\n",
    "        f_z = sliding_window([z], data_length, get_absoldev)\n",
    "\n",
    "        df_processed['XABSOLDEV'] = f_x\n",
    "        df_processed['YABSOLDEV'] = f_y\n",
    "        df_processed['ZABSOLDEV'] = f_z\n",
    "\n",
    "        # COS\n",
    "        f_xy = sliding_window([x, y], data_length, get_cos)\n",
    "        f_yz = sliding_window([y, z], data_length, get_cos)\n",
    "        f_xz = sliding_window([x, z], data_length, get_cos)\n",
    "\n",
    "        df_processed['XYCOS'] = f_xy\n",
    "        df_processed['YZCOS'] = f_yz\n",
    "        df_processed['XZCOS'] = f_xz\n",
    "\n",
    "        # COR\n",
    "        f_xy = sliding_window([x, y], data_length, get_cor)\n",
    "        f_yz = sliding_window([y, z], data_length, get_cor)\n",
    "        f_xz = sliding_window([x, z], data_length, get_cor)\n",
    "\n",
    "        df_processed['XYCOR'] = f_xy\n",
    "        df_processed['YZCOR'] = f_yz\n",
    "        df_processed['XZCOR'] = f_xz\n",
    "\n",
    "        # resultant\n",
    "        res = sliding_window([x, y, z], data_length, get_resultant)\n",
    "\n",
    "        df_processed['RESULTANT'] = res\n",
    "\n",
    "        # X0-X9, Y0-Y9, Z0-Z9\n",
    "        f_x = calc_bindist(x, 10, data_length)\n",
    "        f_y = calc_bindist(y, 10, data_length)\n",
    "        f_z = calc_bindist(z, 10, data_length)\n",
    "\n",
    "        for i in range(10):\n",
    "            x_n = 'X'+str(i)\n",
    "            y_n = 'Y'+str(i)\n",
    "            z_n = 'Z'+str(i)\n",
    "            df_processed[x_n] = f_x[:,i]\n",
    "            df_processed[y_n] = f_y[:,i]\n",
    "            df_processed[z_n] = f_z[:,i]\n",
    "\n",
    "        f_x = compute_mfcc(x)\n",
    "        f_y = compute_mfcc(y)\n",
    "        f_z = compute_mfcc(z)\n",
    "        for i in range(13):\n",
    "            x_n = 'XMFCC'+str(i)\n",
    "            y_n = 'YMFCC'+str(i)\n",
    "            z_n = 'ZMFCC'+str(i)\n",
    "            df_processed[x_n] = f_x[i][0:data_length]\n",
    "            df_processed[y_n] = f_y[i][0:data_length]\n",
    "            df_processed[z_n] = f_z[i][0:data_length]\n",
    "\n",
    "        df_processed['PARTICIPANT'] = df_out['participant_id'][0:data_length]\n",
    "        df_processed['ACTIVITY'] = calc_activity(df_out['activity_code'].to_numpy(), data_length)\n",
    "        df_processed = df_processed[EXTRACTED_FEATURES]\n",
    "        df_processed.to_csv(dst_path+txt, encoding='utf-8', index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0abe5-e46c-4927-a151-089d9b34c2cc",
   "metadata": {},
   "source": [
    "### Feature extraction for phone accelerometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f0fa2d-70f0-4697-a0f1-c0df5695a996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'O': 13, 'P': 14, 'Q': 15, 'R': 16, 'S': 17}\n",
      "Number of Categories 18\n",
      "data length 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| [   51/  51, 00:17<00:00 ]\n"
     ]
    }
   ],
   "source": [
    "src_path=\"../dataset/raw/phone/accel/\"\n",
    "dst_path=\"../dataset/processed/phone/accel/\"\n",
    "extract_feature(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2037790-8087-497e-97e1-3267210a5a66",
   "metadata": {},
   "source": [
    "### Feature extraction for phone gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f254186c-df90-4346-b003-e14480a1375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'O': 13, 'P': 14, 'Q': 15, 'R': 16, 'S': 17}\n",
      "Number of Categories 18\n",
      "data length 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| [   51/  51, 00:16<00:00 ]\n"
     ]
    }
   ],
   "source": [
    "src_path=\"../dataset/raw/phone/gyro/\"\n",
    "dst_path=\"../dataset/processed/phone/gyro/\"\n",
    "extract_feature(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53a3bc-ce99-4474-93dc-9ca88568518a",
   "metadata": {},
   "source": [
    "### Feature extraction for watch accelerometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1cb28e9-4a09-449c-ac93-4996aff6e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'O': 13, 'P': 14, 'Q': 15, 'R': 16, 'S': 17}\n",
      "Number of Categories 18\n",
      "data length 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| [   51/  51, 00:16<00:00 ]\n"
     ]
    }
   ],
   "source": [
    "src_path=\"../dataset/raw/watch/accel/\"\n",
    "dst_path=\"../dataset/processed/watch/accel/\"\n",
    "extract_feature(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83475b7-e6e2-4418-a1a9-e1edbfe12da2",
   "metadata": {},
   "source": [
    "### Feature extraction for watch gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c10a8d3d-1877-4463-aedc-ced961e12d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'O': 13, 'P': 14, 'Q': 15, 'R': 16, 'S': 17}\n",
      "Number of Categories 18\n",
      "data length 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| [   51/  51, 00:16<00:00 ]\n"
     ]
    }
   ],
   "source": [
    "src_path=\"../dataset/raw/watch/gyro/\"\n",
    "dst_path=\"../dataset/processed/watch/gyro/\"\n",
    "extract_feature(src_path, dst_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
